{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 텍스트 파일에서의 토큰 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple_preprocess: tokenize data through Handling punctuations and lowercasing the text \n",
    "from gensim.utils import simple_preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"These guyes are smart students of AI department in Jeonju university.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['these', 'guyes', 'are', 'smart', 'students', 'of', 'ai', 'department', 'in', 'jeonju', 'university']\n"
     ]
    }
   ],
   "source": [
    "# Remove accent marks from tokens using deaccent() function\n",
    "print(simple_preprocess(sample_text, deacc = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 한국어 Word2Vec 만들기\n",
    "* 영화 리뷰 데이터 활용\n",
    "* 참고: https://monetd.github.io/python/nlp/Word-Embedding-Word2Vec-%EC%8B%A4%EC%8A%B5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt    # konlpy 설치 필요(pip install konlpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 가져오기\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n",
    "train_data = pd.read_table('ratings.txt')\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각각의 리뷰에 대한 id값과 실제 리뷰 내용 그리고 긍정/부정 여부를 나타내는 label 값으로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "# 정규 표현식을 통한 한글 외 문자 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 및 불용어 제거 (시간 소요)\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "okt = Okt()\n",
    "tokenized_data = []\n",
    "for sentence in train_data['document']:\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['어리다', '때', '보고', '지금', '다시', '보다', '재밌다', 'ㅋㅋ'],\n",
       " ['디자인',\n",
       "  '을',\n",
       "  '배우다',\n",
       "  '학생',\n",
       "  ',',\n",
       "  '외국',\n",
       "  '디자이너',\n",
       "  '그',\n",
       "  '일군',\n",
       "  '전통',\n",
       "  '을',\n",
       "  '통해',\n",
       "  '발전',\n",
       "  '문화',\n",
       "  '산업',\n",
       "  '부럽다',\n",
       "  '.',\n",
       "  '사실',\n",
       "  '우리나라',\n",
       "  '에서도',\n",
       "  '그',\n",
       "  '어렵다',\n",
       "  '시절',\n",
       "  '끝',\n",
       "  '까지',\n",
       "  '열정',\n",
       "  '을',\n",
       "  '지키다',\n",
       "  '노라노',\n",
       "  '같다',\n",
       "  '전통',\n",
       "  '있다',\n",
       "  '저',\n",
       "  '같다',\n",
       "  '사람',\n",
       "  '꿈',\n",
       "  '을',\n",
       "  '꾸다',\n",
       "  '이루다',\n",
       "  '나가다',\n",
       "  '수',\n",
       "  '있다',\n",
       "  '것',\n",
       "  '감사하다',\n",
       "  '.'],\n",
       " ['폴리스스토리', '시리즈', '1', '부터', '뉴', '까지', '버리다', '하나', '없다', '..', '최고', '.'],\n",
       " ['오다',\n",
       "  '..',\n",
       "  '연기',\n",
       "  '진짜',\n",
       "  '개',\n",
       "  '쩔다',\n",
       "  '..',\n",
       "  '지루하다',\n",
       "  '생각',\n",
       "  '몰입',\n",
       "  '보다',\n",
       "  '..',\n",
       "  '그렇다',\n",
       "  '이렇다',\n",
       "  '진짜',\n",
       "  '영화',\n",
       "  '지'],\n",
       " ['안개', '자욱하다', '밤하늘', '뜨다', '있다', '초승달', '같다', '영화', '.']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_data[:5] # 토큰화된 상위 5개 데이터를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17615, 100)\n"
     ]
    }
   ],
   "source": [
    "# Gensim을 이용하여 Word2Vec 훈련\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences = tokenized_data, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "print(model.wv.vectors.shape)  # 완성된 임베딩 매트릭스의 크기 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('설경구', 0.8955587148666382), ('엄정화', 0.8701022863388062), ('송강호', 0.8641658425331116), ('차승원', 0.8603668808937073), ('김명민', 0.8602263331413269), ('정재영', 0.8549153208732605), ('신들리다', 0.8544403910636902), ('박상민', 0.8537116050720215), ('이요원', 0.8499498963356018), ('다우니', 0.847318172454834)]\n"
     ]
    }
   ],
   "source": [
    "# 완성된 모델을 이용해 “한석규”과 비슷한 단어들을 출력\n",
    "print(model.wv.most_similar(\"한석규\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "konlpy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
